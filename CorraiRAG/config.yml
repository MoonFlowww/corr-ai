environment:
  model_name: "gpt-3.5-turbo"
  temperature: 0
  openai_base_url: "https://api.openai-sb.com/v1"
  openai_api_key: "sb-c4555dc97b5732dc0bed25d8650d4b3fc53fac2ae54e84ee"
  neo4j_uri: "neo4j+s://b21b5510.databases.neo4j.io"
  neo4j_username: "neo4j"
  neo4j_password: "wmGT6XuzYcjSaO_u1sqD3qJsk-IXuWBQwKWeOlS3OUo"

# Document Processing Configuration
document_processing:
  chunk_size: 512  # Maximum characters per text chunk
  overlap: 50  # Overlap between text chunks

# Vector Index Configuration
vector_index:
  index_type: "faiss"  # Choose vector index type (faiss or neo4j)
  faiss_index_file: "faiss_index.index"  # Path to the FAISS index file
  embedding_model: "sentence-transformers/all-MiniLM-L6-v2"  # Model used for vectorization

# Neo4j Configuration
neo4j_graph:
  uri: "neo4j://localhost:7687"
  username: "neo4j"
  password: "your_neo4j_password"
  connection_pool_size: 20  # Connection pool size

# LLM Configuration
llm:
  model_name: "gpt-4-0125-preview"  # Name of the GPT model
  temperature: 0  # Temperature parameter for text generation

# API Configuration
api:
  host: "0.0.0.0"
  port: 8000
  api_prefix: "/v1"

# Logging Configuration
logging:
  level: "INFO"  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
  log_file: "rag_system.log"

# Other Service Configurations (such as cache, queue, etc.)
cache:
  type: "redis"
  host: "localhost"
  port: 6379
  db: 0

# Monitoring and Alerting Configuration
monitoring:
  enabled: true
  endpoint: "http://localhost:9090"
  alert_thresholds:
    query_latency: 200  # ms
    error_rate: 5  # %
